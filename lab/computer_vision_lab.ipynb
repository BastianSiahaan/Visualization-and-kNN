{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jgW7I33T4ej"
      },
      "source": [
        "## Computer Vision\n",
        "\n",
        "Let's do some very basic computer vision. We're going to import the MNIST handwritten digits data and $k$NN to predict values (i.e. \"see/read\").\n",
        "\n",
        "1. To load the data, run the following code in a chunk:\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "df = mnist.load_data('minst.db')\n",
        "train,test = df\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "```\n",
        "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n') # Print the label\n",
        "    print(X_test[i],'\\n') # Print the matrix of values\n",
        "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
        "    plt.show()\n",
        "```\n",
        "OK, those are the data: Labels attached to handwritten digits encoded as a matrix.\n",
        "\n",
        "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
        "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
        "4. Use the reshaped `X_test` and `y_test` data to create a $k$-nearest neighbor classifier of digit. What is the optimal number of neighbors $k$? If you can't determine this, play around with different values of $k$ for your classifier.\n",
        "5. For the optimal number of neighbors, how well does your predictor perform on the test set? Report the accuracy, compute a confusion matrix, and explain your findings.\n",
        "6. For your confusion matrix, which mistakes are most likely? Do you find any interesting patterns?\n",
        "7. So, this is how computers \"see.\" They convert an image into a matrix of values, that matrix becomes a vector in a dataset, and then we deploy ML tools on it as if it was any other kind of tabular data. To make sure you follow this, invent a way to represent a color photo in matrix form, and then describe how you could convert it into tabular data. (Hint: RGB color codes provide a method of encoding a numeric value that represents a color.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "df = mnist.load_data('minst.db')\n",
        "train,test = df\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n')\n",
        "    print(X_test[i],'\\n')\n",
        "    plt.contourf(np.rot90(X_test[i].transpose()))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Jfykh-llUCH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train[0].shape)\n",
        "print(X_test[0].shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "FqrUmYFIULPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "reload = 0\n",
        "\n",
        "if reload == 1:\n",
        "    Z_train = []\n",
        "    for i in range(60000):\n",
        "        row = X_train[i].reshape((1,784))\n",
        "        Z_train.append(row[0])\n",
        "    Z_train = pd.DataFrame(Z_train)\n",
        "    Z_train.to_csv('./data/Z_train.csv')\n",
        "    #\n",
        "    Z_test = []\n",
        "    for i in range(len(y_test)):\n",
        "        row = X_test[i].reshape((1,784))\n",
        "        Z_test.append(row[0])\n",
        "    Z_test = pd.DataFrame(Z_test)\n",
        "    Z_test.to_csv('./data/Z_test.csv')\n",
        "else:\n",
        "    Z_train = pd.read_csv('./data/Z_train.csv')\n",
        "    Z_test = pd.read_csv('./data/Z_test.csv')"
      ],
      "metadata": {
        "id": "AzJwBR3OUQDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "k_bar = 20\n",
        "accuracy = []\n",
        "\n",
        "for k in range(k_bar):\n",
        "    print('Current k: ' , str(k+1))\n",
        "    knn = KNeighborsClassifier(n_neighbors=k+1)\n",
        "    predictor = knn.fit(Z_train.values,y_train)\n",
        "    accuracy.append( predictor.score(Z_test.values,y_test) )\n",
        "\n",
        "accuracy_max = np.max(accuracy)\n",
        "max_index = np.where(accuracy==accuracy_max)[0]\n",
        "k_star = max_index+1\n",
        "print(k_star)\n",
        "\n",
        "plt.plot(np.arange(1,k_bar+1),accuracy)\n",
        "plt.xlabel(\"k\")\n",
        "plt.title(\"optimal k: \"+str(k_star))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D_HFfdzgUXDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "predictor = knn.fit(Z_train.values,y_train)\n",
        "y_hat = predictor.predict(Z_test.values)\n",
        "\n",
        "accuracy = knn.score(Z_test.values,y_test)\n",
        "print('Accuracy: ', accuracy)\n",
        "\n",
        "pd.crosstab(y_test, y_hat)"
      ],
      "metadata": {
        "id": "Ko0j-GriUcW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With \\( k=3 \\), the rule achieves a 90% accuracy on the test set. When errors occur, they often involve misclassifications such as mistaking 4 for 9, 8 for 3, or 7 for 1, which is reasonable. It is impressive that a straightforward algorithm like kNN can perform so well in classifying such intricate data."
      ],
      "metadata": {
        "id": "fCYPSJSzUpzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most frequent misclassifications include confusing a 7 for a 1 (39 times), a 9 for a 7 (40 times), an 8 for a 3 (50 times), a 9 for a 4 (51 times), an 8 for a 5 (45 times), and a 4 for a 9 (81 times). This pattern suggests that these digits share strong visual similarities, making the errors understandable. Even humans occasionally misread these numbers, particularly when they are not clearly written."
      ],
      "metadata": {
        "id": "uxQ778_AU12q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The current dataset represents each pixel in the 28Ã—28 grid with an \"intensity\" value. To incorporate color, we could use three separate matrices to capture the intensity of Red, Green, and Blue channels. These matrices would then be reshaped and combined into a single row, forming tabular data similar to the approach used earlier."
      ],
      "metadata": {
        "id": "kpfGp_nGU2mE"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}